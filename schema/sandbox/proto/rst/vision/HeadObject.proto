package rst.vision;

import "rst/geometry/BoundingBox.proto";
import "rst/tracking/TrackingInfo.proto";
import "rst/vision/Face.proto";
import "rst/math/Vec3DFloat.proto";
import "rst/classification/ClassificationResult.proto";

option java_outer_classname = "HeadObjectType";

// Focus on image coordinate systems (vision-based)
// A head object represented by its ID, location in the image and
// head rotation angles
// id    : head object identifier
// region: head location in the input image

message HeadObject {
    optional tracking.TrackingInfo tracking_info = 1;
    optional geometry.BoundingBox region = 2;
    optional math.Vec3DFloat position = 3;
    // all pose angles are given in degrees
    // pan   : pan head rotation angle, positive: person looks to his right side
    // tilt  : tilt head rotation angle, positive: person looks up
    // roll  : roll head rotation angle, positive: person's head rolled to his right shoulder
    optional math.Vec3DFloat pose = 4;
    // repeated field because in cases of stereo processing there might be faces
    // from both cameras
    message LabeledFace {
        required bytes label = 1;
        required vision.Face face = 2;
    }
    repeated LabeledFace faces = 6;
    optional float speaking_probability = 7;
    // string description of the visual focus of attention of this head
    optional bytes vfoa_target = 8;
    optional classification.ClassificationResult identity = 9;
    optional classification.ClassificationResult gender = 10;
    optional classification.ClassificationResult age = 11;
}
